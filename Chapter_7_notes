# Chapter 7: Coding and Content

Dretske attempts to answer the question of what is a blief so so substantiate an informatic-centric theory of knowledge. He sets the stage for the discussion by saying a dfence needs to describe how a person (or a cat) can process the information that room is cold. While other systesm (thermostats) can generate the information without gaining any knowledge.

The approach is to argue all information-processing systems occupy lower levels of intentionality. But for something to be also knowledge it must occupy higher-order intentional states. To illustrate, Dretske constructs three orders of intentionality. (see Rosenthal 2008, PDF in this directory).

## First order of intentionality

1. All *F*s are *G*
2. *S* has the content that *t* is *F*
3. *S* does **not** have the content that *t* is *G*.

## Second order of intentionality

1. It is a natural law that *F*s are *G*
2. *S* has the content that *t* is *F*
3. *S* does **not** have the content that *t* is *G*.

## Third order of intentionality

1. It is analytically necessary that *F*s be *G*
2. *S* has the content that *t* is *F*
3. *S* does **not** have the content that *t* is *G*.

For Dretske, any propositional content, exhibiting the third order of intentionality a semantic contant (p.173). While a signal does not posses this higher-order intentionality and only operates first order intentionality. With respect to the second order, if *F* and *G* are nomically related  then the fact that *t* is *F* will also have nested within it that *t* is *G*. This also hold a fortiori for analytic implications. That *t* is also *G* is by definition nested in the signal that *t* is *F*, even if I am not aware of it, it has to be there.

For Dretske then, a belief occupies a higher order of intentionality than a structure with respect to its informational content. Both are said to have porpositional content, namely that *s* is *F*. However an informational structure can not have that *t* is *F* as its informational content, without having **all* the information nested in *t's* being *F* inside ie they have first order intentionality. In contrast, nomically or analytically can have the belief that *s* is *F* as its exclusive contant as the rest is inherent a priori. Likewise there is a clear separation from information and meaning. Dretske then argues as both meaning and belief have similar orders of higher order intetionality, then a theory of one is a theory of the other.

**This claims needs further thought, because corelation does not imply automatic causation.**

Hence the next step is to develop semantic contant (third order intentionality) from information bearing structures.  Here he proposes that a strcuture *S* carries the information in the analogue representation that *t* is *F*. But *S* carries more information about *t* that it is just *F*. It carries, nomically or analytically, that *t* is *K* and the fact that *t* is *F* is actually nested within the knowledge of *t* that it is *K*. SO if you know *t* is *K* then it must also be *F*, but if you know *t* is *F* you do not know that it is also *K*. 

The challenge is to decide which of the layers of intentional content provides the semantic content. For Dretske then in the analogue form a structure *S* carries the information *I* and nested within is all the other layers of information, *I'* . There  is nothing to distinguish it in the analgue form. In the digital form only *I* has a representation. The but is *S* only carries the information *I* that *t* is *F* iff if this is the most specific piece of information about *t* that *S* carries.

Dretske hopes to argue that beliefs are generated by how information is encoded by a system not by the actual information itself. So that *t* is a square is encoded in analgue and digital forms. There is a great deal more intetional information nested within the information that *t* is a *square*, (see Fig 7.1, p. 177). 

Key to the argument is that the inner layers of propositional information is implied in the outer inner, but not the opposite. So if I know *t* is a *square* then I know *t* is also a type of rectangle, but if I know *t* is a type of rectangle, I do not know that *t* is a square.

This makes the semantic content unique as it contains porpositional content that the informational layers do not. To Dretske, this suggest as semantic structures have the same high level intentionality as beliefs, they are the ideal information-thereticac analogs of belief.

Of interest is that semantic structures are sensitive or responsive to a particular piece of information. Dretske illustrates this by the claim that *S* contains the semantic belief *t* is a square. Anything that is not nomically or analytically not required for that statement is invisible to *S*.  Hence, *S* would be the same if it were a red square or a blue square as these elements are nested within the analgue claim that *S* states *t* is a square and the color is causally irrelevant. In the digital version with semantic information only the outer layer that *t* is a square is available to be a belief.

**So how does Dretske cope with the reality of blue vs red squares are a thing, or is there some superstructure of semantic beliefs so shape is one belief, color is another etc and the whole belief framework is built up from these primitives? If so there is no mention of this in the text.**

Equally, only the information that *t* is a square is responsible for the semantic structure *S*. The structure carrying the information that *t* is a parallelogram is a different unique semantic struture. So a semantic structure is selectively sensitive to the component of the incoming information that defines the structure's semantic content. Hence a semantic structure may be viewed as a system's interpretation of the incoming information bearing signals.

**Isn't this almost Socrates' theory of forms, where we will have a semantic structure for everything? Equally is a cartoon lion, a photo of a lion and looking at an actual lion the same thing. Humans appear to have nesting within semantic constructs, a nesting which Dretske has stripped out.**

So resolution of the digital image, in the percpetual phase, is dependent on the highlighting of one component to the exclusion of all others. So a signal may lead to the semantic knowledge that *t* is a square, stripping away the knowledge that the square is also red. Equally, an perceptual interpretation may be that *t* is a rectangle, stripping away both the red and square components of the digital information baring signal. 

For Dretske, going from sensing to know necessarily involves stimulus generation and the conversion process necessarily abstracts and generalises from the original sense derived signal. So a signal arrives that *t* is *F*, then the signal must carry the information that *t* is *K*, where being *k* implies that it is *F* and *G*. So the system must abstract from *t* is *K*, then *t* is actually *F*. It must also generalise that the signal is alike other instances of *F*, ie those where it is not derived from *K* (p. 182). 

So a system that displays genuine cognitive properties must assign a sameness of outputs to differences of input (p. 183). Hence a genuine cognitive systems implies a loss of information between its input and the output. It can not be the same as semantic knowledge implies the reductive change from an analgue to a digital signal.

An important point is that it need not be the outer most informational layer of the ring that is the basis of the digital transformation. It is the outer most layer with the most specific information about the nature of *t* that is the semantic content. All other informtion about *t* is nested in this outermostr informational shell of the structure, but there may be other layers of less specific information beyond. 

Dretske therefore amends his definition of semantic content;

That structure *S* has the fact that *t* is *F* as its semantic content is the equivalent of 
1. *S* carries the information that *t* is *F* and
2. *S* carries no other piece of information,  *r* is *G*, which is such that the information *t* is *F* is nested (nomically or analytically) in *r* being *G*.

By this model, then a voltmeter or a TV never has the semantic content as its outer most shell. The information is always nested within the state of the machine, so the machine can never know the semantic content contained within the information structure. Cognition allows the message to be heard by ignoring the messanger. A voltmeter is only the messanger of something elses information.

