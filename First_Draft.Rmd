---
title: "Notes"
author: "Dr Greig Russell"
date: "`r format(Sys.time(), '%d %B, %Y')`"
header-includes:
   - \usepackage{amsthm}
output: 
  pdf_document:
    toc: true
    toc_depth: 2
    number_section: true
    citation_package: natbib
bibliography: Reference.bib
link-citations: yes
lof: true
---
\pagebreak
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
```

# Introduction



# The modern computer
In information science, there is a constant dance between the applied and theoretical branches of the discipline. The work of one underpins the next advance in the other. While electronic computers were created to meet human needs when those needs exceeded the capacity of individual humans, information science preceded and enabled their development. The focus for advancing the capacity of computers or their application to solving human problems ever since has been about developing the hardware and software together with theoretical paradigms. To understand information there requires an understanding of computers. 

Simply put, a computer is the combination of its hardware and software, and its current state of development is an iterative development from the original concepts developed during and before WW2.

## The hardware
In 1945, @von1993first first described the components of what he termed "very high speed automatic digital computing system" (section 1.1), and it has become the standard architecture of the computer.  The concept has not changed since, even if the component level details have changed dramatically. The aim of this computer, called the EDVAC, was to solve non-linear partial differential equations (@von1993first, section 1.2).

The current unified concept of a Central Processing Unit (CPU) served two functions. The first was an arithmetic processor to complete basic mathematical operations. For @@von1993first this also included more complex functions such as sin, cos, log and square root functions. (section 2.2). The second component was the logic controller (section 2.3). The logic controller was responsible for the orderly execution of a specific set of instructions. The central logic controller was responsible for the orderly operation of the computer as a whole, including hardware components, regardless of any specific program that it was running. It was this latter feature that made this the architecture for a general computer, not dedicated to a specific task like some of the earlier machines (such as the "Colossus" of Bentley Park and the WW2 code breakers fame). 

Key to the new design for the EDVAC was the provision of "considerable" memory (section 2.4). Although hilariously small at 34KB by today's standards, such memory allows for the solution to be broken into components for efficient problem solving within a supervising logic tree. It also allowed for interim states of variables to be available between components to be saved (@von1993first, section 2.4). @von1993first   also saw that such generalised computers could be useful for statisticians in regards to the managing of large data samples.  

The computer will require input devices (@von1993first, section 2.6), such as punch cards,  and recording this information by use by the computer.  Note, for this architecture, the recorded information is not available for the computer. Hence, the computer needs a means of moving the data into the working memory or CPU (section 2.7).  Equally, a means of moving the results back to be recorded (section 2.8) and then outputting the results in human-readable forms, such as on a teletype (section 2.9)

```{r VNA, fig.cap = "Von Neumann Architecture", fig.height = 4}
include_graphics("/home/greig/R-projects/Confirmation/VN_Version1.png")
```

## The software
Alan Turing outlined the fundamental functional concepts of a computer in his landmark 1937 paper "On computable numbers, with an application to the Entscheidungsproblem" (@turing1937computable).  The EDVAC was supposed to enable such functions to occur within a general computer, as Turing described.

Turing's computer was not the focus of his paper. Instead, it was a thought experiment that served as a vehicle to address the real issue the Entscheidungsproblem or "halting" problem.  Yet, this description has served as the archetype for what a computer needs to have to be a complete general computer. The term "Turing complete" has been coined to describe any such computer (or language on modern computers with the abstraction of the programming logic from the hardware into the software) that can perform all the functions of a Turing machine. 

The components of a Turing machine are the machine itself and paper tape. The machine consists of a reader/writer head and a set of instructions that depending on the initial state, describe what will happen next.  The paper tape consists of a series of symbols, and in Turing's day this was always numbers but what they are is irrelevant to the operation of Turing's machine.  The machine reads a symbol on the paper tape, and then performs the specified action by the instruction set based on that symbol. This action may be to change the symbol on the tape or move to another place on the tape or even do both (@turing1937computable). 

The paper tape describes the initial state of such a machine. After the machine holts, the paper tape now describes the output of the machine. Turing's research was about whether such machines will always holt and he was able to prove that they did not (@turing1937computable).

For everyone else, Turing's machine is the blueprint of a computer, which was brought to life on physical hardware following the design based on Von Neumann's architecture. 

##The modern computer
Remarkably, this remains the fundamental design of a computer ever since.   The only other significant change was in the 1960s IBM is credited with the introduction of the operating system (OS).   This innovation overcame the practical problem of the instruction set is unique to every computer chip. Changing the hardware meant rewriting all of the software, which as the scale of instruction sets grew exponentially was utterly impractical. 

The OS became an abstraction that took standardised requests from an instruction set and translated them to the system used by the underlying hardware. For software developers, they could write the code once, and it would run across different hardware configurations. For hardware engineers, they could rapidly innovate without breaking all the client's software. 

The standardised model of the computer has become;



## The algorithm is the truth

## Turing machine
## Lambda calculus & functional programming

\begin{equation}
f(k) = {n \choose k} p^{k} (1-p) ^ {n-k}
\end{equation}

# The arms race

## Moores law
## Hardware, software and OS evolution
## Data still static

# Collaboration

## Shannon's communication theory
## The internet
## Fake news

# The ontology of information

## Dretske
## Carnap and Bar Hillel

# The lost counterfactual

## Lewis

# Conclusion

# Bibliography

